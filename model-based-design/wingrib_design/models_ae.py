import torch
from torch import nn


class AEcoder(nn.Module):
    def __init__(self, embed_dim, ndf, ngf):
        super(AEcoder, self).__init__()
        self.encoder = Encoder(ndf, embed_dim)
        self.decoder = Decoder(ngf, embed_dim)

    def forward(self, x):
        z = self.encoder(x)
        y = self.decoder(z)
        return y


class AEcoder3(nn.Module):
    def __init__(self, embed_dim, ndfs, ngfs):
        super(AEcoder3, self).__init__()
        self.ae0 = AEcoder(embed_dim, ndfs, ngfs)
        self.ae1 = AEcoder(embed_dim, ndfs, ngfs)
        self.ae2 = AEcoder(embed_dim, ndfs, ngfs)

    def forward(self, x):
        b = x.shape[0]
        x0 = x[:, :, 0].reshape(b * 3, 2, -1)
        x1 = x[:, :, 1].reshape(b * 3, 2, -1)
        x2 = x[:, :, 2].reshape(b * 3, 2, -1)

        y0 = self.ae0(x0).reshape(b, 3, 1, 2, -1)
        y1 = self.ae0(x1).reshape(b, 3, 1, 2, -1)
        y2 = self.ae0(x2).reshape(b, 3, 1, 2, -1)

        return torch.cat([y0, y1, y2], dim=2)


class Encoder(nn.Module):
    def __init__(self, ndfs, embed_dim):
        super(Encoder, self).__init__()
        ndf1, ndf2, ndf3, ndf4 = ndfs
        self.conv1 = nn.Sequential(
            nn.Conv1d(2, ndf1, 3, 1, 1, bias=False),
            nn.LeakyReLU(0.2, inplace=True),
            # nn.Conv1d(ndf, ndf, 3, 1, 1, bias=False),
            # nn.LeakyReLU(0.2, inplace=True),
        )
        self.conv2 = nn.Sequential(
            nn.Conv1d(ndf1, ndf2, 3, 1, 1, bias=False),
            nn.LeakyReLU(0.2, inplace=True),
            # nn.Conv1d(ndf, ndf, 3, 1, 1, bias=False),
            # nn.LeakyReLU(0.2, inplace=True),
        )
        self.conv3 = nn.Sequential(
            nn.Conv1d(ndf2, ndf2, 3, 1, 1, bias=False),
            nn.LeakyReLU(0.2, inplace=True),
            # nn.Conv1d(ndf * 2, ndf * 2, 3, 1, 1, bias=False),
            # nn.LeakyReLU(0.2, inplace=True),
        )
        self.conv4 = nn.Sequential(
            nn.Conv1d(ndf2, ndf3, 3, 1, 1, bias=False),
            nn.LeakyReLU(0.2, inplace=True),
            # nn.Conv1d(ndf * 2, ndf * 2, 3, 1, 1, bias=False),
            # nn.LeakyReLU(0.2, inplace=True),
        )
        self.downsample = nn.AvgPool1d(2)
        self.conv5 = nn.Conv1d(ndf3, embed_dim, 2, 1, 0, bias=False)

    def forward(self, x):
        b = x.shape[0]
        x = self.conv1(x)
        # x = self.downsample(x)

        x = self.conv2(x)
        x = self.downsample(x)

        x = self.conv3(x)
        x = self.downsample(x)

        x = self.conv4(x)
        x = self.downsample(x)

        x = self.conv5(x)

        return x


class Decoder(nn.Module):
    def __init__(self, ngfs, embed_dim):
        super(Decoder, self).__init__()
        ngf1, ngf2, ngf3, ngf4 = ngfs
        self.upsample = nn.UpsamplingNearest2d(scale_factor=2)

        self.conv1 = nn.Sequential(
            nn.ConvTranspose1d(embed_dim, ngf4, 2, 1, 0, bias=False),
            nn.LeakyReLU(0.2, inplace=True),
        )

        self.conv2 = nn.Sequential(
            # nn.Conv1d(ngf * 2, ngf * 2, 3, 1, 1, bias=False),
            # nn.LeakyReLU(0.2, inplace=True),
            nn.Conv1d(ngf4, ngf3, 3, 1, 1, bias=False),
            nn.LeakyReLU(0.2, inplace=True),
        )
        self.conv3 = nn.Sequential(
            # nn.Conv1d(ngf * 2, ngf * 2, 3, 1, 1, bias=False),
            # nn.LeakyReLU(0.2, inplace=True),
            nn.Conv1d(ngf3, ngf2, 3, 1, 1, bias=False),
            nn.LeakyReLU(0.2, inplace=True),
        )
        self.conv4 = nn.Sequential(
            # nn.Conv1d(ngf * 1, ngf * 1, 3, 1, 1, bias=False),
            # nn.LeakyReLU(0.2, inplace=True),
            nn.Conv1d(ngf2, ngf1, 3, 1, 1, bias=False),
            nn.LeakyReLU(0.2, inplace=True),
        )
        self.conv5 = nn.Sequential(
            # nn.Conv1d(ngf, ngf, 3, 1, 1, bias=False),
            # nn.LeakyReLU(0.2, inplace=True),
            nn.Conv1d(ngf1, 2, 3, 1, 1, bias=False),
            nn.Tanh(),
        )

    def forward(self, x):
        x = self.conv1(x)

        x = self.upsample(x)
        x = self.conv2(x)

        x = self.upsample(x)
        x = self.conv3(x)

        x = self.upsample(x)
        x = self.conv4(x)

        # x = self.upsample(x)
        x = self.conv5(x)

        return x


if __name__ == '__main__':
    from copy import deepcopy
    from tqdm import tqdm
    import numpy as np
    ndfs = [32, 32, 64, 64]
    ngfs = [32, 32, 64, 64]
    embed = 24
    ae = AEcoder(embed, ndfs, ngfs)
    n_params = sum([p.numel() for p in ae.parameters()])
    print(n_params)
    hyper_dict = {}
    for e in tqdm(range(1, 25)):
        err = np.inf
        prev_n = np.inf
        hyperparam_e = []
        for a in range(28, 64, 2):
            for b in range(a, 64, 2):
                for c in range(b, 64, 2):
                    for d in range(c, 64, 2):
                        ndfs = [a, b, c, d]
                        ngfs = [a, b, c, d]
                        ae = AEcoder(e, ndfs, ngfs)
                        cur_n_params = sum([p.numel() for p in ae.parameters()])
                        # if abs(n_params - cur_n_params) <= err:
                        #     if abs(n_params - cur_n_params) == err:
                        #         if cur_n_params <= n_params:
                        #             hyperparam_e.append(deepcopy(ndfs))
                        #     else:
                        #         err = abs(n_params - cur_n_params)
                        #         prev_n = cur_n_params
                        #         hyperparam_e = [deepcopy(ndfs)]
                        # if 0 <= (n_params - cur_n_params) <= err:
                        #     if (n_params - cur_n_params) == err:
                        #         hyperparam_e.append(deepcopy(ndfs))
                        #     else:
                        #         err = (n_params - cur_n_params)
                        #         hyperparam_e = [deepcopy(ndfs)]
                        if 0 <= abs(n_params - cur_n_params) <= 64 and cur_n_params <= n_params:
                            hyperparam_e.append(deepcopy(ndfs))
                            # print(hyperparam_e)

        hyper_dict[e] = deepcopy(hyperparam_e)

    for k, v in hyper_dict.items():
        print(k, [(vi, sum([p.numel() for p in AEcoder(k, vi, vi).parameters()])) for vi in v])



"""

 1 [([13, 14, 14, 16], 3744)]
 2 [([5, 16, 16, 16], 3740), ([9, 14, 16, 17], 3744), ([10, 12, 18, 19], 3742), ([13, 13, 15, 17], 3740)]
 3 [([4, 15, 17, 18], 3741), ([6, 15, 16, 17], 3741)]
 4 [([4, 14, 18, 18], 3744), ([7, 14, 16, 18], 3740), ([8, 14, 15, 19], 3743), ([9, 12, 18, 18], 3744), ([11, 13, 15, 18], 3741), ([12, 13, 14, 19], 3741)]
 5 [([9, 12, 17, 19], 3741), ([9, 14, 15, 16], 3742), ([10, 13, 16, 16], 3743), ([11, 11, 18, 18], 3741), ([11, 14, 14, 15], 3740), ([13, 13, 14, 16], 3741)]
 6 [([4, 13, 18, 19], 3741), ([5, 14, 16, 19], 3744), ([5, 15, 15, 18], 3741), ([11, 11, 17, 19], 3744), ([11, 14, 14, 14], 3744), ([12, 12, 16, 16], 3744)]
 7 [([4, 14, 17, 17], 3743), ([9, 12, 16, 19], 3742)]
 8 [([8, 14, 14, 17], 3742), ([10, 11, 17, 18], 3743), ([11, 13, 14, 16], 3741), ([12, 13, 13, 17], 3744)]
 9 [([4, 13, 17, 18], 3741), ([8, 14, 14, 16], 3744), ([9, 13, 14, 18], 3741), ([10, 11, 16, 19], 3741), ([10, 11, 17, 17], 3744), ([11, 13, 14, 15], 3741)]
10 [([4, 13, 17, 17], 3740), ([8, 14, 14, 15], 3742), ([9, 13, 14, 17], 3743), ([10, 11, 16, 18], 3743), ([10, 13, 13, 18], 3743)]
11 [([9, 13, 14, 16], 3741), ([10, 11, 16, 17], 3741), ([10, 12, 14, 18], 3740), ([10, 13, 13, 17], 3744), ([12, 13, 13, 14], 3741)]
12 [([5, 13, 16, 16], 3741), ([10, 13, 13, 16], 3741), ([11, 11, 15, 17], 3744)]
13 [([4, 12, 16, 19], 3742), ([4, 12, 17, 17], 3743), ([6, 13, 15, 16], 3743)]
14 [([5, 12, 16, 17], 3744), ([7, 13, 14, 16], 3741), ([8, 13, 13, 17], 3744)]
15 [([5, 14, 14, 15], 3744), ([6, 12, 15, 17], 3741), ([7, 12, 14, 18], 3744), ([8, 12, 13, 19], 3741)]
16 [([7, 9, 17, 19], 3744), ([8, 12, 14, 16], 3744), ([9, 13, 13, 14], 3741), ([10, 12, 12, 18], 3744)]
17 [([5, 9, 18, 18], 3741), ([5, 13, 14, 16], 3741), ([6, 11, 16, 16], 3743), ([6, 13, 13, 17], 3744)]
18 [([4, 11, 15, 19], 3744), ([4, 14, 14, 14], 3744), ([5, 11, 15, 18], 3741), ([6, 11, 14, 19], 3741), ([7, 8, 18, 18], 3744), ([7, 9, 16, 19], 3741), ([7, 11, 14, 18], 3741), ([7, 13, 13, 15], 3744), ([8, 11, 14, 17], 3741), ([9, 11, 13, 18], 3741), ([9, 11, 14, 16], 3741), ([10, 11, 13, 17], 3744), ([10, 11, 14, 15], 3741), ([11, 11, 12, 18], 3741), ([11, 11, 14, 14], 3741), ([12, 12, 12, 14], 3744)]
19 [([5, 7, 19, 19], 3742)]
20 [([4, 9, 17, 18], 3743), ([4, 13, 13, 17], 3744), ([6, 10, 16, 16], 3740), ([7, 12, 13, 16], 3740), ([8, 12, 12, 17], 3740), ([9, 10, 14, 17], 3742), ([10, 10, 13, 18], 3742)]
21 [([6, 10, 15, 17], 3741), ([6, 13, 13, 14], 3741), ([7, 10, 14, 18], 3744), ([8, 10, 13, 19], 3741), ([12, 12, 12, 12], 3744)]
22 [([7, 8, 16, 18], 3740), ([8, 8, 15, 19], 3743), ([9, 11, 13, 15], 3740), ([10, 11, 12, 16], 3743), ([11, 11, 11, 17], 3740), ([11, 11, 12, 15], 3741)]
23 [([4, 10, 14, 19], 3744), ([4, 12, 12, 19], 3742), ([4, 12, 14, 15], 3740), ([5, 12, 12, 18], 3744), ([6, 9, 16, 16], 3743), ([7, 12, 13, 14], 3744), ([8, 12, 13, 13], 3743)]
24 [([5, 9, 16, 16], 3741), ([6, 6, 18, 18], 3744), ([8, 8, 16, 16], 3744), ([9, 10, 13, 16], 3744), ([10, 10, 12, 17], 3744)]



1  [([32, 42, 60, 62], 40264), ([32, 44, 58, 58], 40276), ([34, 44, 56, 60], 40288), ([36, 44, 54, 62], 40276), ([38, 42, 58, 58], 40264), ([38, 46, 50, 60], 40312), ([38, 46, 52, 54], 40280), ([40, 40, 60, 60], 40320), ([40, 42, 56, 60], 40276), ([40, 46, 48, 62], 40264), ([40, 46, 50, 56], 40280), ([42, 42, 54, 62], 40264), ([42, 46, 48, 58], 40256), ([44, 44, 52, 54], 40316)]
2  [([30, 44, 58, 60], 40312), ([30, 46, 56, 56], 40300), ([32, 44, 56, 62], 40312), ([32, 46, 54, 58], 40312), ([34, 40, 62, 62], 40276), ([34, 46, 52, 60], 40300), ([34, 48, 48, 62], 40304), ([36, 46, 50, 62], 40264), ([36, 48, 48, 58], 40312), ([36, 48, 50, 52], 40320), ([38, 48, 48, 54], 40320), ([40, 44, 54, 54], 40284), ([42, 44, 52, 56], 40296), ([44, 44, 50, 58], 40284)]
3  [([28, 46, 56, 58], 40296), ([28, 48, 52, 60], 40320), ([28, 48, 54, 54], 40260), ([28, 50, 50, 56], 40272), ([30, 46, 54, 60], 40296), ([30, 48, 50, 62], 40284), ([30, 48, 52, 56], 40272), ([30, 50, 50, 52], 40272), ([32, 46, 52, 62], 40272), ([32, 48, 50, 58], 40260), ([38, 40, 60, 60], 40296), ([38, 44, 54, 56], 40284), ([40, 40, 58, 62], 40308), ([40, 44, 52, 58], 40284), ([42, 44, 50, 60], 40260)]
4  [([28, 46, 54, 62], 40288), ([32, 40, 62, 62], 40268), ([34, 42, 58, 60], 40268), ([34, 44, 56, 56], 40280), ([36, 42, 56, 62], 40268), ([36, 44, 54, 58], 40292), ([38, 44, 52, 60], 40280), ([40, 42, 56, 56], 40268), ([40, 46, 48, 58], 40316), ([40, 46, 50, 52], 40284), ([42, 42, 54, 58], 40280), ([42, 46, 46, 60], 40268), ([42, 46, 48, 54], 40284), ([44, 46, 46, 56], 40260)]
5  [([32, 44, 56, 58], 40308), ([32, 46, 54, 54], 40296), ([34, 44, 54, 60], 40308), ([34, 46, 52, 56], 40308), ([36, 40, 60, 60], 40272), ([36, 44, 52, 62], 40284), ([36, 46, 50, 58], 40296), ([38, 40, 58, 62], 40284), ([38, 42, 56, 58], 40320), ([38, 46, 48, 60], 40260), ([38, 48, 48, 50], 40316), ([40, 42, 54, 60], 40320), ([42, 42, 52, 62], 40296), ([42, 44, 52, 52], 40280), ([44, 44, 50, 54], 40292)]
6  [([28, 48, 52, 56], 40320), ([28, 50, 50, 52], 40260), ([30, 40, 62, 62], 40260), ([30, 46, 54, 56], 40284), ([30, 48, 50, 58], 40308), ([32, 46, 52, 58], 40284), ([32, 48, 48, 60], 40272), ([32, 48, 50, 54], 40260), ([34, 46, 50, 60], 40260), ([40, 40, 58, 58], 40284), ([40, 44, 52, 54], 40272), ([42, 44, 48, 62], 40320), ([42, 44, 50, 56], 40272)]
7  [([28, 42, 60, 60], 40284), ([28, 46, 54, 58], 40280), ([30, 42, 58, 62], 40296), ([30, 46, 52, 60], 40268), ([36, 40, 58, 62], 40260), ([36, 44, 54, 54], 40260), ([38, 44, 52, 56], 40272), ([38, 46, 50, 52], 40320), ([40, 44, 50, 58], 40260), ([40, 46, 48, 54], 40320), ([42, 46, 46, 56], 40296), ([42, 46, 48, 50], 40264), ([44, 46, 46, 52], 40264)]
8  [([28, 44, 56, 60], 40256), ([28, 46, 52, 62], 40260), ([32, 42, 58, 58], 40304), ([34, 42, 56, 60], 40316), ([34, 44, 54, 56], 40280), ([34, 46, 52, 52], 40268), ([36, 42, 54, 62], 40304), ([36, 44, 52, 58], 40280), ([36, 46, 50, 54], 40280), ([36, 48, 48, 50], 40304), ([38, 44, 50, 60], 40256), ([38, 46, 46, 62], 40272), ([38, 46, 48, 56], 40268), ([40, 40, 56, 60], 40256), ([40, 42, 54, 56], 40292), ([42, 42, 52, 58], 40292)]
9  [([28, 48, 52, 52], 40272), ([30, 44, 56, 56], 40296), ([30, 48, 48, 60], 40320), ([30, 48, 50, 54], 40284), ([32, 44, 54, 58], 40308), ([32, 48, 48, 56], 40272), ([34, 44, 52, 60], 40296), ([34, 46, 48, 62], 40296), ([36, 44, 50, 62], 40260), ([42, 42, 50, 62], 40296), ([44, 44, 46, 60], 40284), ([46, 46, 46, 46], 40296)]
10 [([28, 48, 48, 62], 40264), ([32, 44, 52, 62], 40320), ([40, 44, 48, 60], 40320), ([40, 46, 48, 50], 40276), ([42, 44, 46, 62], 40260), ([42, 46, 46, 52], 40276)]
11 [([32, 46, 52, 52], 40316), ([34, 48, 48, 50], 40292), ([36, 42, 54, 58], 40264), ([36, 46, 48, 56], 40316), ([38, 44, 48, 62], 40316), ([38, 46, 46, 58], 40280), ([42, 44, 50, 50], 40300), ([44, 44, 48, 52], 40312)]
12 [([28, 48, 50, 54], 40308), ([30, 46, 52, 54], 40308), ([30, 48, 48, 56], 40296), ([32, 46, 50, 56], 40308), ([34, 38, 60, 62], 40260), ([34, 46, 48, 58], 40284), ([36, 42, 52, 62], 40308), ([38, 40, 56, 58], 40296), ([38, 42, 54, 54], 40272), ([40, 40, 54, 60], 40296), ([40, 42, 52, 56], 40284), ([40, 44, 50, 52], 40296), ([42, 42, 50, 58], 40272), ([42, 44, 48, 54], 40296), ([44, 44, 44, 62], 40296), ([44, 44, 46, 56], 40272), ([44, 46, 46, 46], 40272)]
13 [([28, 42, 56, 62], 40280), ([28, 46, 52, 56], 40308), ([30, 44, 54, 56], 40276), ([30, 46, 50, 58], 40296), ([32, 40, 58, 60], 40292), ([32, 44, 52, 58], 40276), ([32, 46, 48, 60], 40260), ([34, 40, 56, 62], 40292), ([36, 44, 52, 52], 40288), ([38, 44, 50, 54], 40300), ([38, 46, 48, 50], 40288), ([40, 42, 50, 60], 40312), ([40, 44, 48, 56], 40288), ([40, 46, 46, 52], 40288), ([42, 42, 48, 62], 40264), ([42, 42, 52, 52], 40300)]
14 [([28, 46, 50, 60], 40292), ([30, 42, 56, 58], 40260), ([30, 44, 52, 60], 40312), ([32, 38, 60, 62], 40268), ([32, 42, 54, 60], 40260), ([32, 44, 50, 62], 40276), ([32, 48, 48, 50], 40280), ([34, 44, 52, 54], 40312), ([36, 44, 50, 56], 40312), ([38, 44, 48, 58], 40288)]
15 [([28, 48, 48, 56], 40320), ([30, 40, 58, 60], 40260), ([32, 40, 56, 62], 40260), ([34, 36, 62, 62], 40284), ([34, 46, 46, 60], 40296), ([36, 44, 48, 60], 40296), ([44, 44, 44, 58], 40284)]
16 [([30, 38, 60, 62], 40276), ([30, 42, 56, 56], 40316), ([32, 46, 46, 62], 40272), ([32, 48, 48, 48], 40320), ([34, 42, 52, 60], 40316), ([34, 44, 48, 62], 40312), ([36, 40, 56, 56], 40304), ([36, 42, 50, 62], 40280), ([36, 46, 48, 50], 40300), ([38, 40, 54, 58], 40316), ([38, 46, 46, 52], 40300), ([40, 40, 52, 60], 40304), ([42, 44, 44, 60], 40264)]
17 [([28, 42, 54, 62], 40280), ([30, 40, 58, 58], 40316), ([30, 48, 48, 50], 40268), ([32, 46, 50, 50], 40264), ([34, 40, 54, 62], 40316), ([34, 42, 54, 54], 40296), ([34, 46, 48, 52], 40276), ([36, 42, 52, 56], 40308), ([36, 46, 46, 54], 40264), ([38, 42, 50, 58], 40296), ([40, 40, 54, 54], 40260), ([40, 42, 48, 60], 40260), ([44, 44, 46, 50], 40260)]
18 [([28, 38, 60, 62], 40284), ([28, 44, 52, 58], 40272), ([30, 46, 50, 52], 40260), ([32, 46, 48, 54], 40260), ([36, 40, 54, 58], 40260), ([38, 42, 48, 62], 40308), ([38, 42, 52, 52], 40284), ([40, 42, 50, 54], 40296), ([42, 42, 48, 56], 40284)]
19 [([28, 40, 58, 58], 40276), ([28, 44, 50, 62], 40292), ([28, 46, 50, 54], 40264), ([30, 40, 56, 60], 40288), ([30, 42, 52, 62], 40320), ([30, 44, 52, 54], 40268), ([30, 48, 48, 48], 40296), ([32, 40, 54, 62], 40276), ([32, 44, 50, 56], 40268), ([34, 46, 48, 50], 40312), ([36, 46, 46, 52], 40312), ([38, 38, 56, 58], 40296), ([38, 44, 48, 52], 40256), ([42, 42, 46, 60], 40280), ([42, 42, 50, 50], 40280), ([44, 44, 46, 48], 40292)]
20 [([28, 44, 52, 56], 40320), ([28, 48, 48, 50], 40256), ([30, 42, 54, 56], 40292), ([30, 44, 50, 58], 40308), ([30, 46, 50, 50], 40288), ([32, 42, 52, 58], 40292), ([32, 44, 48, 60], 40272), ([32, 46, 48, 52], 40300), ([34, 42, 50, 60], 40268), ([34, 44, 50, 52], 40272), ([34, 46, 46, 54], 40288), ([36, 40, 54, 56], 40304), ([36, 44, 48, 54], 40272), ([38, 40, 52, 58], 40304), ([40, 40, 50, 60], 40280), ([40, 42, 46, 62], 40320), ([40, 44, 48, 48], 40272), ([42, 44, 46, 50], 40284), ([44, 44, 44, 52], 40272)]
21 [([28, 46, 50, 52], 40296), ([30, 44, 48, 62], 40308), ([30, 44, 52, 52], 40296), ([30, 46, 48, 54], 40296), ([32, 44, 50, 54], 40308), ([32, 46, 46, 56], 40272), ([34, 40, 52, 62], 40308), ([34, 44, 48, 56], 40296), ([36, 38, 56, 58], 40272), ([36, 44, 46, 58], 40260), ([38, 38, 54, 60], 40272), ([38, 44, 48, 50], 40284), ([40, 44, 46, 52], 40284), ([42, 44, 44, 54], 40260), ([44, 44, 46, 46], 40308)]
22 [([28, 46, 48, 56], 40300), ([28, 48, 48, 48], 40272), ([30, 42, 54, 54], 40320), ([30, 46, 46, 58], 40264), ([34, 42, 50, 58], 40320), ([34, 44, 46, 60], 40280), ([34, 44, 50, 50], 40292), ([36, 36, 58, 60], 40256), ([36, 42, 48, 60], 40284), ([36, 44, 48, 52], 40304), ([38, 44, 46, 54], 40292), ([40, 44, 44, 56], 40256), ([42, 42, 44, 62], 40316), ([42, 44, 46, 48], 40304), ([44, 44, 44, 50], 40304)]
23 [([28, 40, 56, 58], 40284), ([28, 42, 52, 60], 40300), ([28, 46, 46, 60], 40264), ([28, 46, 50, 50], 40312), ([30, 40, 54, 60], 40284), ([30, 42, 50, 62], 40264), ([32, 34, 62, 62], 40264), ([32, 40, 52, 62], 40260), ([32, 44, 46, 62], 40308), ([32, 46, 46, 54], 40312), ([34, 42, 52, 52], 40268), ([36, 38, 56, 56], 40300), ([36, 42, 50, 54], 40280), ([36, 44, 46, 56], 40308), ([38, 38, 54, 58], 40312), ([38, 42, 48, 56], 40268), ([38, 44, 44, 58], 40260), ([38, 44, 48, 48], 40296), ([40, 40, 52, 52], 40256), ([40, 44, 46, 50], 40308), ([42, 44, 44, 52], 40296)]
24 [([30, 46, 46, 56], 40308), ([32, 36, 58, 62], 40260), ([34, 36, 58, 60], 40272), ([34, 40, 54, 54], 40260), ([36, 36, 56, 62], 40272), ([36, 36, 58, 58], 40284), ([36, 40, 52, 56], 40272), ([36, 44, 44, 60], 40272), ([36, 44, 48, 50], 40320), ([38, 40, 50, 58], 40260), ([38, 42, 46, 60], 40284), ([38, 44, 46, 52], 40320), ([40, 44, 44, 54], 40296), ([42, 44, 46, 46], 40308), ([44, 44, 44, 48], 40320)]
 
"""